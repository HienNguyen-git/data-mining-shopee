{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and packages for the project \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "from time import sleep\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm #process bar\n",
    "from underthesea import sentiment #check comment + -\n",
    "\n",
    "print('- Finish importing packages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.binary_location = \"C:\\\\Program Files\\\\Google\\\\Chrome Beta\\\\Application\\\\chrome.exe\"\n",
    "driver = webdriver.Chrome(chrome_options = options, executable_path=r'C:\\chromedriver_win32\\chromedriver.exe')\n",
    "wait = WebDriverWait(driver,20)\n",
    "\n",
    "url = \"https://shopee.vn/\"\n",
    "shopee_url = 'https://shopee.vn'\n",
    "\n",
    "# Login to shopee by QR code\n",
    "login_url = \"https://shopee.vn/buyer/login/qr?next=https%3A%2F%2Fshopee.vn%2Fuser%2Fpurchase%2F\"\n",
    "driver.get(login_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_url = \"https://shopee.vn/mall/brands/\"\n",
    "driver.get(brands_url)\n",
    "#c1\n",
    "page_source = BeautifulSoup(driver.page_source)\n",
    "sections = page_source.find_all('div', {\"class\":[\"official-shop-brand-list__section-content\"]})\n",
    "order = 1\n",
    "count = 0\n",
    "shop_list = []\n",
    "headers = ['Order', 'Name', 'URL']\n",
    "\n",
    "def handle_add_shop(order,name,shop_URL):\n",
    "    shop_list.append({headers[0]:order,headers[1]:name,headers[2]:shop_URL})\n",
    "    print(\"Added new shop: \")\n",
    "    print(\"%d - %s - %s\"%(order,name,shop_URL))\n",
    "\n",
    "for section in sections:\n",
    "    order_section = section.findAll('div',class_=\"full-brand-list-item\")\n",
    "    if(order==101): # Get enough data\n",
    "        break\n",
    "    for shop in order_section:\n",
    "        cmt_flag = False\n",
    "        if(order==101):\n",
    "            break\n",
    "\n",
    "        # Random order shop\n",
    "        is_next = random.randint(1,10)\n",
    "        if(is_next%2==0):\n",
    "            continue\n",
    "\n",
    "        shop_URL = shopee_url + shop.find('a', class_=\"full-brand-list-item__brand-cover-image\").get('href') # Get shop url\n",
    "        name = shop.find('div',class_=\"full-brand-list-item__brand-name\").text # Get shop name\n",
    "        \n",
    "        #Click each shop to check quantity > 100 and comment > 20000\n",
    "        try:\n",
    "            driver.get(shop_URL)\n",
    "            print('- Accessing shop: ', shop_URL)\n",
    "            sleep(2)\n",
    "            driver.execute_script('window.scrollTo(0, 0);') #scroll to the end of the page\n",
    "            sleep(1)\n",
    "        except TimeoutException:\n",
    "            print(\"***************************\")\n",
    "            print(\"Loading took too much time!\")\n",
    "            print(\"***************************\")\n",
    "            continue\n",
    "\n",
    "        loop_page_source = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "        items = loop_page_source.find_all('div',{\"class\":[\"section-seller-overview__item-text-value\"]})\n",
    "        if(items):\n",
    "            if(items[0] and items[8]):\n",
    "                # Check product quantity\n",
    "                product_quantity = items[0]\n",
    "                product_quantity = product_quantity.text \n",
    "\n",
    "                # Check comment\n",
    "                comment_quantity = items[8]\n",
    "                comment_items = comment_quantity.text.split(' ')\n",
    "                if(len(comment_items)!=4):\n",
    "                    continue\n",
    "                comment_quantity = comment_items[1][1:]\n",
    "                if(not comment_quantity.isdecimal()):\n",
    "                    tmp = comment_quantity.split(\",\")\n",
    "                    cmt_quantity = tmp[0] if len(tmp)>1 else tmp[0][:-1]\n",
    "                    if(int(cmt_quantity)>=20):\n",
    "                        cmt_flag = True\n",
    "                if(cmt_flag):\n",
    "                    if(not product_quantity.isdecimal()): # Quantity > 100\n",
    "                        handle_add_shop(order,name,shop_URL)\n",
    "                        count+=1\n",
    "                        order+=1  \n",
    "                    elif(int(product_quantity)>=100): # Check shop product quantity is greater than 100 or not\n",
    "                        handle_add_shop(order,name,shop_URL)\n",
    "                        count+=1\n",
    "                        order+=1    \n",
    "\n",
    "                sleep(3)\n",
    "\n",
    "                if(count==10): # \n",
    "                    count = 0\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "print(\"Finished crawling data!\")\n",
    "\n",
    "with open('ShopeeMall.csv', 'w',encoding='utf-8',  newline = '') as file_output:\n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for shop in shop_list:\n",
    "        writer.writerow(shop)\n",
    "\n",
    "print('Mission Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers = ['Order', 'Name', 'URL', \"Sales\"]\n",
    "update_data = []\n",
    "char_dic = {'k':1000,'r': 1000000}\n",
    "\n",
    "count = 0\n",
    "sales = 0\n",
    "\n",
    "for shop in tqdm(df,desc=\"Processing: \"):\n",
    "    product_list_url = []\n",
    "    count = 0\n",
    "    total = 0\n",
    "    try:\n",
    "        my_url = shop[2]+\"?page=0&sortBy=sales\"\n",
    "        driver.get(my_url)\n",
    "        print('- Accessing shop: ', shop[2])\n",
    "        sleep(2)\n",
    "        \n",
    "    except:\n",
    "        print(\"***************************\")\n",
    "        print(\"Loading took too much time!\")\n",
    "        print(\"***************************\")\n",
    "        continue\n",
    "\n",
    "    print('-- Getting data....')\n",
    "\n",
    "    for i in range( 3):\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to the end of the page\n",
    "        sleep(0.3)\n",
    "        loop_page_source = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "        sleep(0.3)\n",
    "        old_page_source = driver.page_source\n",
    "\n",
    "        items = loop_page_source.find('div',class_=\"shop-search-result-view\").find_all('a',href=True)\n",
    "\n",
    "        product_list_url.append(items)\n",
    "        wait.until(EC.element_to_be_clickable((By.CLASS_NAME,\"shopee-icon-button--right\"))).click()\n",
    "        sleep(0.4)\n",
    "        new_page_source = driver.page_source\n",
    "        if new_page_source == old_page_source:\n",
    "            break\n",
    "        sleep(2)\n",
    "    print('-- Finished get data')\n",
    "\n",
    "    print(\"--- Access product pages\")\n",
    "    print(\"************************\")\n",
    "    for page in product_list_url:\n",
    "        if(count==101):\n",
    "            break\n",
    "        for products in page:\n",
    "            count+=1\n",
    "            if(count==101):\n",
    "                break\n",
    "            price = products.find('span',class_=\"_3TJGx5\").text\n",
    "            amount_raw = products.find('div',class_=\"_2R-Crv\")\n",
    "\n",
    "            price = price.replace(\".\",\"\")\n",
    "\n",
    "            if(not amount_raw): # ko bán cái nào\n",
    "                continue\n",
    "            elif (len(amount_raw.text)==0):\n",
    "                continue\n",
    "\n",
    "            tmp = amount = amount_raw.text.split(\" \")[2].split(\"/\")[0].replace(\",\",\".\")\n",
    "            \n",
    "            if tmp[-1].isdecimal():\n",
    "                amount = float(tmp)\n",
    "            else:\n",
    "                if(tmp[-1]==\"k\"):\n",
    "                    amount = float(tmp[:-1])*char_dic[tmp[-1]] #1k sp\n",
    "                else:\n",
    "                    amount = float(tmp[:-2])*char_dic[tmp[-1]] #1tr sp\n",
    "\n",
    "            total += float(price)* amount\n",
    "\n",
    "    update_data.append({headers[0]:shop[0],headers[1]:shop[1],headers[2]:shop[2],headers[3]:total})\n",
    "    print(\"************************\")\n",
    "\n",
    "print(\"Finished crawling data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('ShopeeMall.csv')\n",
    "df = np.array(raw)\n",
    "#c3\n",
    "headers = ['Order', 'Name', 'URL', \"Negative\",\"Positive\"]\n",
    "update_data = []\n",
    "\n",
    "count = 0\n",
    "negative = 0\n",
    "positive = 0\n",
    "total_cmt = 0\n",
    "tmp_neg = 0\n",
    "tmp_pos = 0\n",
    "\n",
    "for shop in tqdm(df,desc=\"Processing: \"):\n",
    "    product_list_url = []\n",
    "    count = 0\n",
    "    negative = 0\n",
    "    positive = 0\n",
    "\n",
    "    try:\n",
    "        my_url = shop[2]+\"?page=0&sortBy=sales\"\n",
    "        driver.get(my_url)\n",
    "        print('- Accessing shop: ', shop[2])\n",
    "        sleep(2)\n",
    "    except:\n",
    "        print(\"***************************\")\n",
    "        print(\"Loading took too much time!\")\n",
    "        print(\"***************************\")\n",
    "        continue\n",
    "\n",
    "    print('-- Getting data....')\n",
    "\n",
    "    for i in range(4): # 1 page 30 product => 4/120 , need 100 product each shop\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to end page\n",
    "        sleep(0.5)\n",
    "        loop_page_source = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "        sleep(0.5)\n",
    "        old_page_source = driver.page_source\n",
    "\n",
    "        items = loop_page_source.find('div',class_=\"shop-search-result-view\").find_all('a',href=True)\n",
    "\n",
    "        product_list_url.append(items)\n",
    "        wait.until(EC.element_to_be_clickable((By.CLASS_NAME,\"shopee-icon-button--right\"))).click() #qua từng trang sp bằng next\n",
    "        sleep(0.3)\n",
    "\n",
    "        new_page_source = driver.page_source\n",
    "        if new_page_source == old_page_source: #hết qua trang đc \n",
    "            break\n",
    "        sleep(2)\n",
    "        \n",
    "    print('-- Finished get data')\n",
    "\n",
    "    print(\"--- Access product pages\")\n",
    "    print(\"************************\")\n",
    "    # need 200 cmt each product\n",
    "    for page in product_list_url:\n",
    "        for products in tqdm(page,desc=\"Current/Total\"):\n",
    "            \n",
    "            total_cmt = 0\n",
    "            tmp_neg = 0\n",
    "            tmp_pos = 0\n",
    "\n",
    "            count+=1\n",
    "            if(count==101):\n",
    "                break\n",
    "            product_url = url + products.get('href')\n",
    "            \n",
    "            driver.get(product_url)\n",
    "            sleep(2)\n",
    "\n",
    "            while(1):\n",
    "                driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to end page\n",
    "                sleep(0.5)\n",
    "                product_detail_page_source = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "                sleep(0.5)\n",
    "                old_page_source = driver.page_source\n",
    "\n",
    "                comments = product_detail_page_source.find_all('div', class_=\"Em3Qhp\") # Get comment\n",
    "                \n",
    "                if(len(comments)==0): # Section have no comments\n",
    "                    if total_cmt==0: # First comment section has no comment\n",
    "                        sleep(2)\n",
    "                    break\n",
    "\n",
    "                for cmt in comments:\n",
    "                    my_text = cmt.text.strip()\n",
    "                    if(sentiment(my_text)==\"negative\"):\n",
    "                        tmp_neg+=1\n",
    "                    else:\n",
    "                        tmp_pos+=1\n",
    "\n",
    "                total_cmt = tmp_neg+tmp_pos\n",
    "\n",
    "                try:\n",
    "                    wait.until(EC.element_to_be_clickable((By.CLASS_NAME,\"shopee-icon-button--right\"))).click() #qua từng trang cmt bằng next\n",
    "                except TimeoutException:\n",
    "                    continue\n",
    "                sleep(0.3)\n",
    "\n",
    "                new_page_source = driver.page_source\n",
    "                if new_page_source == old_page_source or total_cmt>=200: #đã qua hết trang hoặc đủ 200 cmt\n",
    "                    negative+= tmp_neg\n",
    "                    positive+= tmp_pos\n",
    "                    break\n",
    "\n",
    "    update_data.append({headers[0]:shop[0],headers[1]:shop[1],headers[2]:shop[2],headers[3]:negative,headers[4]:positive})\n",
    "    print(\"************************\")\n",
    "\n",
    "print(\"Finished crawling data!\")\n",
    "\n",
    "with open('ShopeeMallSentiment.csv', 'w', encoding='utf-8',  newline = '') as file_output:\n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for shop in update_data:\n",
    "        writer.writerow(shop)\n",
    "\n",
    "print('Mission Completed!')\n",
    "\n",
    "with open('ShopeeMallSales.csv', 'w',  newline = '') as file_output:\n",
    "    \n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for shop in update_data:\n",
    "        writer.writerow(shop)\n",
    "\n",
    "print('Mission Completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c4\n",
    "df = pd.read_csv('ShopeeMall.csv')\n",
    "arraydf = np.array(df)\n",
    "\n",
    "headers = ['Order', 'Name', 'URL','Type']\n",
    "result = []\n",
    "\n",
    "for a in arraydf:\n",
    "    # access link shop\n",
    "    driver.get(a[-1])\n",
    "    sleep(2)\n",
    "    print('Access shop:' +a[1])\n",
    "\n",
    "    #access product\n",
    "    shop_detail = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    link_firstpd = shop_detail.find_all('a',{'data-sqe': 'link'})\n",
    "    linkproduct = shopee_url +  link_firstpd[0].get('href')\n",
    "    driver.get(linkproduct)\n",
    "    sleep(2)\n",
    "\n",
    "    #take type\n",
    "    product_detail = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    types_shop = product_detail.find_all('a',class_ = 'ClhheV')\n",
    "    typeshop = types_shop[1].text\n",
    "\n",
    "    result.append({headers[0]:a[0],headers[1]:a[1],headers[2]:a[2],headers[3]:typeshop})\n",
    "    \n",
    "print(result)\n",
    "\n",
    "with open('ShopeeMallType.csv', 'w', encoding='utf-8', newline = '') as file_output:\n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for shoptype in result:\n",
    "        writer.writerow(shoptype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c5\n",
    "headers = ['Order', 'Name', 'URL', \"Rating\",\"Chat Response (%)\",\"Follower\"]\n",
    "char_dic = {'k':1000,'r': 1000000}\n",
    "update_data = []\n",
    "\n",
    "for shop in tqdm(df):\n",
    "\n",
    "    try:\n",
    "        driver.get(shop[2])\n",
    "        print('- Accessing shop: ', shop[2])\n",
    "        sleep(2)\n",
    "        driver.execute_script('window.scrollTo(0, 0);') #scroll to the end of the page\n",
    "        sleep(1)\n",
    "    except TimeoutException:\n",
    "        print(\"***************************\")\n",
    "        print(\"Loading took too much time!\")\n",
    "        print(\"***************************\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    loop_page_source = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "    items = loop_page_source.find_all('div',{\"class\":[\"section-seller-overview__item-text-value\"]})\n",
    "    \n",
    "    # Clean data\n",
    "    if(len(items)==12):\n",
    "        rating_raw = items[9].text\n",
    "        chat_response_raw = items[4].text\n",
    "        follower_raw = items[7].text.replace(\",\",\".\")\n",
    "    else:\n",
    "        rating_raw = items[11].text\n",
    "        chat_response_raw = items[4].text\n",
    "        follower_raw = items[9].text.replace(\",\",\".\")\n",
    "\n",
    "    # Get rating of chat response \n",
    "    chat_response = chat_response_raw.split(\" \")[0][:-1]\n",
    "\n",
    "    # Get the number of follower\n",
    "    unit_char = follower_raw[-1]\n",
    "    if(unit_char.isdecimal()):\n",
    "        follower = int(follower_raw[:-1])\n",
    "    else:\n",
    "        value = \"\"\n",
    "        if(unit_char==\"k\"):\n",
    "            value = follower_raw[:-1]\n",
    "        else:\n",
    "            value = follower_raw[:-2]\n",
    "            \n",
    "        follower = float(value)*char_dic[unit_char]\n",
    "\n",
    "    # Get rating\n",
    "    rating = rating_raw.split(\" \")[0]\n",
    "\n",
    "\n",
    "    update_data.append({headers[0]:shop[0],headers[1]:shop[1],headers[2]:shop[2],headers[3]:rating,headers[4]:chat_response,headers[5]:follower})\n",
    "\n",
    "print(\"Finished crawling data!\")\n",
    "\n",
    "with open('ShopeeMall5.csv', 'w',  newline = '') as file_output:\n",
    "    \n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for shop in update_data:\n",
    "        writer.writerow(shop)\n",
    "\n",
    "print('Mission Completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c6\n",
    "df = pd.read_csv('ShopeeMall.csv')\n",
    "arraydf = np.array(df)\n",
    "\n",
    "headers = ['Order', 'Name', 'URL','Type','Quantity Discount','Quantity Type Product','Year Join']\n",
    "result = []\n",
    "\n",
    "for a in arraydf:\n",
    "    # access link shop\n",
    "    driver.get(a[-1])\n",
    "    sleep(2)\n",
    "    print('Access shop:' +a[1])\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to end page\n",
    "    sleep(1)\n",
    "    shop_detail = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    sleep(1)\n",
    "    \n",
    "    #year\n",
    "    shop_info = shop_detail.find_all('div',{'class': 'section-seller-overview__item-text-value'})\n",
    "    shop_info_year = shop_info[-1].text\n",
    "    year_split = shop_info_year.split(' ')\n",
    "    if(year_split[1]== 'tháng'):\n",
    "        yearint = int(year_split[0])\n",
    "        year = math.floor(yearint/12)\n",
    "    else: \n",
    "        year = year_split[0]\n",
    "\n",
    "    #count discount\n",
    "    discount_quantity = shop_detail.find_all('div',{'class': '_7ojJBF'})\n",
    "\n",
    "    #count type product\n",
    "    type_product_quantity = shop_detail.find_all('div',{'class': '_1_yYlR'})\n",
    "\n",
    "    #access product\n",
    "    link_firstpd = shop_detail.find('a',{'data-sqe': 'link'}).get('href')\n",
    "    linkproduct = shopee_url +  link_firstpd\n",
    "    driver.get(linkproduct)\n",
    "    sleep(2)\n",
    "\n",
    "    #take type\n",
    "    product_detail = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    types_shop = product_detail.find_all('a',class_ = 'ClhheV')\n",
    "    typeshop = types_shop[1].text\n",
    "    \n",
    "    result.append({headers[0]:a[0],\n",
    "    headers[1]:a[1],\n",
    "    headers[2]:a[2],\n",
    "    headers[3]:typeshop,\n",
    "    headers[4]:len(discount_quantity),\n",
    "    headers[5]:len(type_product_quantity)-1,\n",
    "    headers[6]:year})\n",
    "    \n",
    "print(result)\n",
    "\n",
    "with open('ShopeeMallUpdate.csv', 'w', encoding='utf-8', newline = '') as file_output:\n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for res in result:\n",
    "        writer.writerow(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
